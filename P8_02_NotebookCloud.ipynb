{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexis\\anaconda3\\lib\\site-packages\\requests\\__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import io\n",
    "from io import StringIO \n",
    "import pyarrow\n",
    "\n",
    "import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import sys\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.rdd import RDD\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "#from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.sql.functions import udf, pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import urllib.request\n",
    "\n",
    "#!pip install findspark\n",
    "import findspark\n",
    "\n",
    "import pyspark\n",
    "pyspark.__version__\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.layers import Dense, GlobalMaxPooling2D, Flatten\n",
    "\n",
    "import sklearn.decomposition\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT, DenseVector\n",
    "\n",
    "import json\n",
    "import boto.s3, boto.s3.key\n",
    "#!pip install boto3\n",
    "import boto3\n",
    "import pickle\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette version Cloud nous allons reprendre en très grande partie ce qui a déjà été fait, nous modifierons l'accès aux données, maintenant nous récupérerons les données sur S3 et non plus sur la machine locale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName('Projet8_AWS').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-19LUCQ2G:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Projet8_AWS</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1cf611bd0a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons passer à la classification des images, dans un premier temps nous utiliserons SparkML et ensuite nous regarderons ce que nous obtiendrons avec un réseau déjà enraîné (comme VGG16):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps nous allons récupérer le chemin du dossier des images d'entraînement (les images étant déjà divisé en dossier d'entraînement et de test). Nous avons également 2 dossiers à notre disposition, un dossier contenant des images de taille quelconque et un dossier contenant des images à la taille 100x100, nous nous servirons de ces images pour SparkML, pour l'entrainement avec VGG16 nous utiliserons sans doute l'autre dossier puisqu'il faudra redimmensionner les images pour l'entrée du réseau.\n",
    "\n",
    "De même pour la suite nous n'utiliserons pas tous les dossiers, nous n'en utiliserons que 6, dont 3 dossiers de pomme afin de voir les résultats de la classification et de ne pas perdre trop de temps en calcul, notamment avec le réseau de neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_path = s3://imageprojet8oc/ImageAWS/\n"
     ]
    }
   ],
   "source": [
    "img_dir = 's3://imageprojet8oc/ImageAWS/'\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(\"imageprojet8oc\")\n",
    "\n",
    "print('dataset_path =', img_dir)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons les catégories a notre disposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorie = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de catégorie:  4 \n",
      "\n",
      "Catégories à notre disposition: \n",
      "  -  Grape_Blue\n",
      "  -  Kaki\n",
      "  -  Lychee\n",
      "  -  Strawberry\n"
     ]
    }
   ],
   "source": [
    "for objet in bucket.objects.filter(Prefix=\"ImageAWS\"):\n",
    "    if objet.key.split('/')[1] not in categorie:\n",
    "        categorie.append(str(objet.key.split('/')[1]))\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "print('Nombre de catégorie: ', len(categorie), '\\n')\n",
    "print('Catégories à notre disposition: ')\n",
    "for i in range(len(categorie)):\n",
    "    print('  - ', categorie[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme mentionné plus haut nous confronterons le machine learning à des catégories assez éloignées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons de voir à quoi ressemble les images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred = boto3.Session().get_credentials()\n",
    "ACCESS_KEY = cred.access_key\n",
    "SECRET_KEY = cred.secret_key\n",
    "\n",
    "AWS_KEY = ACCESS_KEY\n",
    "SEC_KEY = SECRET_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session(aws_access_key_id = AWS_KEY,\n",
    "                                aws_secret_access_key = SEC_KEY)\n",
    "s3_client = session.client(service_name = 's3', region_name = 'eu-west-3')\n",
    "\n",
    "response = s3_client.generate_presigned_url('get_object',\n",
    "                                            Params = {'Bucket': 'imageprojet8oc',\n",
    "                                                      'Key': \"ImageAWS/Kaki/12_100.jpg\"}\n",
    "                                           )\n",
    "resp = urllib.request.urlopen(response)\n",
    "img_show = Image.open(io.BytesIO(resp.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=100x100 at 0x1CF61D635E0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la suite nous utiliserons le modèle MobileNetV2, je ne vais pas ici remontrer l'architecture de ce dernier puisque ça a déjà été fait.\n",
    "\n",
    "Comme pour la version avec le chargement des images locales, nous allons charger nos images au format binary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de lire des fichiers binaires à partir d’Amazon S3 en utilisant le préfixe ci-dessous au chemin d’accès:\n",
    "\n",
    "    - s3:\\\\ = > Première génération\n",
    "    - s3n:\\\\ => deuxième génération\n",
    "    - s3a:\\\\ => Troisième génération\n",
    "    \n",
    "Dans notre cas nous sommes à la 3ème génération, donc nous préfixerons le chemin de nos images avec 's3a:\\\\\\\\' .\n",
    "\n",
    "Ainsi que des dépendances et des informations d’identification tierces, dans notre cas nous devrons charger les .jars suivant:\n",
    "\n",
    "    - org.apache.hadoop:hadoop-aws:3.2.0\n",
    "    - com.amazonaws:aws-java-sdk-core-1.12.134\n",
    "    - com.amazonaws:aws-java-sdk-dynamodb-1.12.134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dirS3 = 's3a://imageprojet8oc/ImageAWS/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sc.setSystemProperty('com.amazonaws.services.s3.enableV4', 'true')\n",
    "sc._jsc.hadoopConfiguration().set('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:3.2.0')\n",
    "#sc._jsc.hadoopConfiguration().set('spark.jars.packages', 'com.amazonaws:aws-java-sdk:1.12.117')\n",
    "#sc._jsc.hadoopConfiguration().set('spark.jars.packages', 'com.amazonaws:aws-java-sdk-s3-1.12.120')\n",
    "sc._jsc.hadoopConfiguration().set('spark.jars.packages', 'com.amazonaws:aws-java-sdk-core-1.12.134')\n",
    "sc._jsc.hadoopConfiguration().set('spark.jars.packages', 'com.amazonaws:aws-java-sdk-dynamodb-1.12.134')\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.eu-west-3.amazonaws.com\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", AWS_KEY)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", SEC_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesALL_df = spark.read.format(\"binaryFile\") \\\n",
    "                    .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
    "                    .option(\"recursiveFileLookup\", \"true\") \\\n",
    "                    .load(img_dirS3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+\n",
      "|                path|   modificationTime|length|             content|\n",
      "+--------------------+-------------------+------+--------------------+\n",
      "|s3a://imageprojet...|2022-01-16 23:06:32|  6307|[FF D8 FF E0 00 1...|\n",
      "|s3a://imageprojet...|2022-01-16 23:03:34|  6298|[FF D8 FF E0 00 1...|\n",
      "|s3a://imageprojet...|2022-01-16 23:06:20|  6295|[FF D8 FF E0 00 1...|\n",
      "|s3a://imageprojet...|2022-01-16 23:06:23|  6295|[FF D8 FF E0 00 1...|\n",
      "|s3a://imageprojet...|2022-01-16 23:06:13|  6290|[FF D8 FF E0 00 1...|\n",
      "+--------------------+-------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imagesALL_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+\n",
      "|path                                            |\n",
      "+------------------------------------------------+\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/168_100.jpg|\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/194_100.jpg|\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/186_100.jpg|\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/192_100.jpg|\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/172_100.jpg|\n",
      "+------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imagesALL_df.select('path').show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant chercher à récupérer les labels pour chaques images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelAll0 = imagesALL_df.withColumn(\"Label0\", split(imagesALL_df['path'], \"//\").getItem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+\n",
      "|Label0                                    |\n",
      "+------------------------------------------+\n",
      "|imageprojet8oc/ImageAWS/Lychee/168_100.jpg|\n",
      "+------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelAll0.select('Label0').show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesALL_dfLabel = labelAll0.withColumn(\"Label\", split(labelAll0['Label0'], \"/\").getItem(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesALL_dfLabel = imagesALL_dfLabel.select('path', 'content', 'Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|                path|             content| Label|\n",
      "+--------------------+--------------------+------+\n",
      "|s3a://imageprojet...|[FF D8 FF E0 00 1...|Lychee|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imagesALL_dfLabel.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|     Label|count|\n",
      "+----------+-----+\n",
      "|Grape_Blue|  245|\n",
      "|Strawberry|  245|\n",
      "|      Kaki|  245|\n",
      "|    Lychee|  245|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imagesALL_dfLabel.groupBy(\"Label\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récpérons maintenant l'index des différents Label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_indexer = StringIndexer(inputCol=\"Label\", outputCol=\"Label_index\")\n",
    "label_indexer_transformer = label_indexer.fit(imagesALL_dfLabel)\n",
    "imagesALL_dfLabel = label_indexer_transformer.transform(imagesALL_dfLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+-----------+\n",
      "|                path|             content| Label|Label_index|\n",
      "+--------------------+--------------------+------+-----------+\n",
      "|s3a://imageprojet...|[FF D8 FF E0 00 1...|Lychee|        2.0|\n",
      "+--------------------+--------------------+------+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imagesALL_dfLabel.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons bien récupérer l'index des labels de nos images, passons à la suite.\n",
    "\n",
    "Commencons par prétraiter nos images, en les redimmensionnant. Ce redimmensionnement se fera à l'appel de l'image, nous aurions pu transformer nos images directement et les enregistrer dans un nouveau dossier, mais cela prendrait trop de temps et surtout si la base de données change il faudra retransformer ces images \"à la main\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(content):\n",
    "    image = PIL.Image.open(io.BytesIO(content))\n",
    "    imageResize = image.resize([224, 224])\n",
    "    imageArray = img_to_array(imageResize)\n",
    "    preprocessingImage = preprocess_input(imageArray)\n",
    "    return preprocessingImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utiliserons les poids de ImageNet, le modèle a déjà était entraîné sur des images de fruits, donc il n'y aurait pas d'intérêt à refaire un entraînement depuis le début."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_MobileNetV2():\n",
    "    model = MobileNetV2(include_top = False, input_shape=(224, 224, 3), weights = \"imagenet\", pooling = 'max')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant récupérer les features de chaques images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_series(model, content_series):\n",
    "    input = np.stack(content_series.map(preprocess))\n",
    "    preds = model.predict(input)\n",
    "    output = [p.flatten() for p in preds]\n",
    "    return pd.Series(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Spark\\spark-3.1.2-bin-hadoop3.2\\python\\pyspark\\sql\\pandas\\functions.py:389: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\n",
    "def featurize_udf(content_series_iter):\n",
    "    model = model_MobileNetV2()\n",
    "    for content_series in content_series_iter:\n",
    "        yield featurize_series(model, content_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = imagesALL_dfLabel.select(\"path\", 'Label', 'Label_index', featurize_udf(\"content\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'optimiser notre code nous allons enregistrer features_df en mémoire, ça nous permettra d'éviter de réaliser des actions deux fois (ici l'appel à featurize_udf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[path: string, Label: string, Label_index: double, featurize_udf(content): array<float>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----------+----------------------+\n",
      "|                path| Label|Label_index|featurize_udf(content)|\n",
      "+--------------------+------+-----------+----------------------+\n",
      "|s3a://imageprojet...|Lychee|        2.0|  [5.899542, 6.0, 0...|\n",
      "+--------------------+------+-----------+----------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df.withColumnRenamed(\"featurize_udf(content)\", \"Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----------+--------------------+\n",
      "|                path| Label|Label_index|            Features|\n",
      "+--------------------+------+-----------+--------------------+\n",
      "|s3a://imageprojet...|Lychee|        2.0|[5.899542, 6.0, 0...|\n",
      "+--------------------+------+-----------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons le forme de nos données Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurefd = features_df.select('Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurefd_Panda = featurefd.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featurefd_Panda['Features'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous devons convertir nos features au format 'org.apache.spark.ml.linalg.VectorUDT' dans un premier temps, pour pouvoir utiliser l'ACP de Pyspark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversionVectorUDT = udf(lambda feature: Vectors.dense(feature), VectorUDT())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df.withColumn(\"VectorUdt\", conversionVectorUDT('Features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----------+--------------------+--------------------+\n",
      "|                path| Label|Label_index|            Features|           VectorUdt|\n",
      "+--------------------+------+-----------+--------------------+--------------------+\n",
      "|s3a://imageprojet...|Lychee|        2.0|[5.899542, 6.0, 0...|[5.89954185485839...|\n",
      "+--------------------+------+-----------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "acp_train, acp_test = features_df.randomSplit([0.7, 0.3], seed = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la suite nous allons réduire la dimension de nos données, nous avons tracer la courbe d'inertie, nous avons dans un premier temps pris un nombre élevé pour k, nous avons pris k = 75, puis nous avons tracer la courbe, le code sera donné en commentaire mais ne sera pas utiliser ici, nous afficherons la courbe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(k = 75, inputCol = 'VectorUdt', outputCol = 'X_acp')\n",
    "#model = pca.fit(acp_train)\n",
    "#acp_df = model.transform(acp_train)\n",
    "\n",
    "#nombreK = 0\n",
    "#somme = 0\n",
    "#listeI = []\n",
    "#listeSomme = []\n",
    "#for i in range(len(model.explainedVariance)):\n",
    "#    if somme < 0.75:\n",
    "#        somme = somme + model.explainedVariance[i]\n",
    "#        listeI.append(i)\n",
    "#        listeSomme.append(somme)\n",
    "#        nombreK += 1\n",
    "#\n",
    "#print(somme)\n",
    "#print(nombreK)\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.plot(listeI, listeSomme)\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {
    "graphe%20inertie.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![graphe%20inertie.png](attachment:graphe%20inertie.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la suite, à la vue de ce graphe nous prendrons donc k = 2, d'après la méthode du coude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(k = 2, inputCol = 'VectorUdt', outputCol = 'X_acp')\n",
    "model = pca.fit(acp_train)\n",
    "acp_df = model.transform(acp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----------+--------------------+--------------------+--------------------+\n",
      "|                path| Label|Label_index|            Features|           VectorUdt|               X_acp|\n",
      "+--------------------+------+-----------+--------------------+--------------------+--------------------+\n",
      "|s3a://imageprojet...|Lychee|        2.0|[5.502656, 6.0, 0...|[5.50265598297119...|[-38.764044931983...|\n",
      "+--------------------+------+-----------+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acp_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant passer à la classification après un entraînement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter = 20, regParam = 0.05, elasticNetParam = 0.3, labelCol = \"Label_index\", featuresCol = 'X_acp')\n",
    "p_model = lr.fit(acp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "acp_Train = model.transform(acp_train)\n",
    "predictions1 = p_model.transform(acp_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+------+-----------+----------+\n",
      "|path                                            |Label |Label_index|prediction|\n",
      "+------------------------------------------------+------+-----------+----------+\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/134_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/137_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/164_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/167_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/169_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/171_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/175_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/177_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/184_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/187_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/192_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/193_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/199_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/204_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/208_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/213_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/214_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/140_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/143_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/146_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/155_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/174_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/180_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/181_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/182_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/185_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/190_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/191_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/201_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/202_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/203_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/205_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/206_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/207_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/209_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/215_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/224_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/239_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/245_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/246_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/247_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/129_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/135_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/136_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/144_100.jpg|Lychee|2.0        |2.0       |\n",
      "+------------------------------------------------+------+-----------+----------+\n",
      "only showing top 45 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions1.select(\"path\", \"Label\", \"Label_index\", \"prediction\").show(45, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluatorF1 = MulticlassClassificationEvaluator(labelCol = \"Label_index\", predictionCol = \"prediction\", metricName = \"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 =  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 = \", evaluatorF1.evaluate(predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluatorAccuracy = MulticlassClassificationEvaluator(labelCol = \"Label_index\", predictionCol = \"prediction\", metricName = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = \", evaluatorAccuracy.evaluate(predictions1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons maintenant sur les donées de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "acp_Test = model.transform(acp_test)\n",
    "predictions = p_model.transform(acp_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+------+-----------+----------+\n",
      "|path                                            |Label |Label_index|prediction|\n",
      "+------------------------------------------------+------+-----------+----------+\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/138_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/168_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/170_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/172_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/173_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/176_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/183_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/186_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/188_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/194_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/195_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/196_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/197_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/211_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/212_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/142_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/147_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/189_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/200_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/210_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/230_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/243_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/248_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/128_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/139_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/141_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/145_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/156_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/157_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/217_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/232_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/234_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/238_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/244_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/254_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/118_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/126_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/133_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/149_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/150_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/152_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/160_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/166_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/227_100.jpg|Lychee|2.0        |2.0       |\n",
      "|s3a://imageprojet8oc/ImageAWS/Lychee/252_100.jpg|Lychee|2.0        |2.0       |\n",
      "+------------------------------------------------+------+-----------+----------+\n",
      "only showing top 45 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"path\", \"Label\", \"Label_index\", \"prediction\").show(45, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que des erreurs existe, ce qui n'est pas étonnant à la vue des classes que nous avons prises.\n",
    "\n",
    "Pour évaluer notre classification multi-classes, nous utiliserons un modèle qui évaluera les prédictions. Nous utiliserons MulticlassClassificationEvaluator avec les métriques F1 et Accuracy.\n",
    "\n",
    "F1 est une moyenne pondérée des scores de précision et de rappel qui sont:\n",
    "\n",
    "    - Précision : Correspond au nombre d'images correctement attribuées à la classe i par rapport au nombre total d'images       prédites comme appartenant à la classe i.\n",
    "    \n",
    "    - Rappel : Correspond au nombre d'images correctement attribuées à la classe i par rapport au nombre total d'images           appartenant à la classe i.   \n",
    "    \n",
    "La mesure F1 est à préférer si nos données sont déséquilibrées, ici ce ne sera pas le cas car nos classes ont un nombre d'images assez proche, comme nous allons voir, mais nous ne savons pas ce qu'il en sera demain et c'est pour cette raison nous évaluerons la précision et F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|     Label|count|\n",
      "+----------+-----+\n",
      "|Grape_Blue|   76|\n",
      "|Strawberry|   61|\n",
      "|      Kaki|   63|\n",
      "|    Lychee|   85|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.groupBy(\"Label\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que la classe Mangoustan est assez déséquilibrée par rapport aux autres, la métrique F1 trouve son intérêt ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluatorF1 = MulticlassClassificationEvaluator(labelCol = \"Label_index\", predictionCol = \"prediction\", metricName = \"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 =  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 = \", evaluatorF1.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluatorAccuracy = MulticlassClassificationEvaluator(labelCol = \"Label_index\", predictionCol = \"prediction\", metricName = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = \", evaluatorAccuracy.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que nos résultats sont très bons puisque nos images sont parfaitement classées, ce qui est logique au final puisque les classes sont très différentes.\n",
    "\n",
    "Mais si d'aventure nous obtenions des résultats moyen, nous pourrions utiliser les fonctions ParamGridBuilder et CrossValidator, qui vont correspondre aux classes GridSearchCV et CrossValidation de python (en faisant un rapide raccourci).\n",
    "\n",
    "Nous nous focaliserions sur la métrique F1 pour les raisons évoquées plus haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paramGrid = (ParamGridBuilder()\n",
    "#  .addGrid(lr.regParam, [0.01, 0.1, 0.5]) \\\n",
    "#  .addGrid(lr.maxIter, [10, 20, 50]) \\\n",
    "#  .addGrid(lr.elasticNetParam, [0.0, 0.8]) \\\n",
    "#  .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crossval = CrossValidator(estimator = lr,\n",
    "#                          estimatorParamMaps = paramGrid,\n",
    "#                          evaluator = evaluatorF1,\n",
    "#                          numFolds = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelOpt = crossval.fit(acp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictionsOpt = modelOpt.transform(acp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"F1 Opt = \", evaluatorF1.evaluate(predictionsOpt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les 2 fonctions devraient opérer une amélioration, nous pourrions peut être l'améliorer encore un peu en choisissant plus de paramètre a tester. Si aucune amélioration n'est réalisé il faudrait réfléchir à utiliser un autre modèle, fournir plus d'image d'entraînement ou revoir votre méthode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons convertir notre fichier au format Pandas afin que nous puissions l'utiliser aussi bien en pyspark qu'en python à l'avenir si besoin.\n",
    "\n",
    "Récupérons dans un premier temps l'adresse du dossier de résultat. Nous utiliserons une nouvelle fois 's3a://' pour accéder au dossier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultat_dir = 's3a://imageprojet8oc/resultat/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultattoPandas = predictions.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>Label</th>\n",
       "      <th>Label_index</th>\n",
       "      <th>Features</th>\n",
       "      <th>VectorUdt</th>\n",
       "      <th>X_acp</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s3a://imageprojet8oc/ImageAWS/Lychee/138_100.jpg</td>\n",
       "      <td>Lychee</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[6.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.2470893859863...</td>\n",
       "      <td>[6.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.2470893859863...</td>\n",
       "      <td>[-38.21556039642781, -2.9845226576518264]</td>\n",
       "      <td>[-0.5940715083834257, -2.0947826501635456, 1.9...</td>\n",
       "      <td>[0.057220457988209926, 0.012758533601474227, 0...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3a://imageprojet8oc/ImageAWS/Lychee/168_100.jpg</td>\n",
       "      <td>Lychee</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[5.899541854858398, 6.0, 0.0, 0.0, 0.005040168...</td>\n",
       "      <td>[5.899541854858398, 6.0, 0.0, 0.0, 0.005040168...</td>\n",
       "      <td>[-38.404451165085405, -4.8425670906523095]</td>\n",
       "      <td>[-0.5442814313648258, -2.1996719915121323, 2.0...</td>\n",
       "      <td>[0.05650213015354228, 0.010792892105981245, 0....</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3a://imageprojet8oc/ImageAWS/Lychee/170_100.jpg</td>\n",
       "      <td>Lychee</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[4.7932586669921875, 6.0, 0.0, 0.0, 0.0, 2.465...</td>\n",
       "      <td>[4.7932586669921875, 6.0, 0.0, 0.0, 0.0, 2.465...</td>\n",
       "      <td>[-37.8919829556127, -4.104653537854926]</td>\n",
       "      <td>[-0.5482549938613935, -2.1478075003315404, 1.9...</td>\n",
       "      <td>[0.058314259054227456, 0.011778715572324726, 0...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s3a://imageprojet8oc/ImageAWS/Lychee/172_100.jpg</td>\n",
       "      <td>Lychee</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[4.484482765197754, 6.0, 0.0, 0.0, 0.0, 0.7102...</td>\n",
       "      <td>[4.484482765197754, 6.0, 0.0, 0.0, 0.0, 0.7102...</td>\n",
       "      <td>[-38.102428854778296, -3.735262137494534]</td>\n",
       "      <td>[-0.5671110683435229, -2.1327420095989407, 1.9...</td>\n",
       "      <td>[0.05760185002735362, 0.012036259808208442, 0....</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s3a://imageprojet8oc/ImageAWS/Lychee/173_100.jpg</td>\n",
       "      <td>Lychee</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[4.615333557128906, 6.0, 0.0, 0.0, 0.0, 0.7182...</td>\n",
       "      <td>[4.615333557128906, 6.0, 0.0, 0.0, 0.0, 0.7182...</td>\n",
       "      <td>[-37.69734099271417, -5.361362452073927]</td>\n",
       "      <td>[-0.5029341223213685, -2.211227161362889, 2.02...</td>\n",
       "      <td>[0.05887957371640522, 0.010667494233172805, 0....</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               path   Label  Label_index  \\\n",
       "0  s3a://imageprojet8oc/ImageAWS/Lychee/138_100.jpg  Lychee          2.0   \n",
       "1  s3a://imageprojet8oc/ImageAWS/Lychee/168_100.jpg  Lychee          2.0   \n",
       "2  s3a://imageprojet8oc/ImageAWS/Lychee/170_100.jpg  Lychee          2.0   \n",
       "3  s3a://imageprojet8oc/ImageAWS/Lychee/172_100.jpg  Lychee          2.0   \n",
       "4  s3a://imageprojet8oc/ImageAWS/Lychee/173_100.jpg  Lychee          2.0   \n",
       "\n",
       "                                            Features  \\\n",
       "0  [6.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.2470893859863...   \n",
       "1  [5.899541854858398, 6.0, 0.0, 0.0, 0.005040168...   \n",
       "2  [4.7932586669921875, 6.0, 0.0, 0.0, 0.0, 2.465...   \n",
       "3  [4.484482765197754, 6.0, 0.0, 0.0, 0.0, 0.7102...   \n",
       "4  [4.615333557128906, 6.0, 0.0, 0.0, 0.0, 0.7182...   \n",
       "\n",
       "                                           VectorUdt  \\\n",
       "0  [6.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.2470893859863...   \n",
       "1  [5.899541854858398, 6.0, 0.0, 0.0, 0.005040168...   \n",
       "2  [4.7932586669921875, 6.0, 0.0, 0.0, 0.0, 2.465...   \n",
       "3  [4.484482765197754, 6.0, 0.0, 0.0, 0.0, 0.7102...   \n",
       "4  [4.615333557128906, 6.0, 0.0, 0.0, 0.0, 0.7182...   \n",
       "\n",
       "                                        X_acp  \\\n",
       "0   [-38.21556039642781, -2.9845226576518264]   \n",
       "1  [-38.404451165085405, -4.8425670906523095]   \n",
       "2     [-37.8919829556127, -4.104653537854926]   \n",
       "3   [-38.102428854778296, -3.735262137494534]   \n",
       "4    [-37.69734099271417, -5.361362452073927]   \n",
       "\n",
       "                                       rawPrediction  \\\n",
       "0  [-0.5940715083834257, -2.0947826501635456, 1.9...   \n",
       "1  [-0.5442814313648258, -2.1996719915121323, 2.0...   \n",
       "2  [-0.5482549938613935, -2.1478075003315404, 1.9...   \n",
       "3  [-0.5671110683435229, -2.1327420095989407, 1.9...   \n",
       "4  [-0.5029341223213685, -2.211227161362889, 2.02...   \n",
       "\n",
       "                                         probability  prediction  \n",
       "0  [0.057220457988209926, 0.012758533601474227, 0...         2.0  \n",
       "1  [0.05650213015354228, 0.010792892105981245, 0....         2.0  \n",
       "2  [0.058314259054227456, 0.011778715572324726, 0...         2.0  \n",
       "3  [0.05760185002735362, 0.012036259808208442, 0....         2.0  \n",
       "4  [0.05887957371640522, 0.010667494233172805, 0....         2.0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultattoPandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '0CN07PGTH1GKPEFG',\n",
       "  'HostId': 'pqPNP+o1z9bNiveLcs5JZzN9rcI7fKNfJZhT9rXa2BTXmdu13WZxOvN0Ytl73EPQv9BYQYhZrq0=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'pqPNP+o1z9bNiveLcs5JZzN9rcI7fKNfJZhT9rXa2BTXmdu13WZxOvN0Ytl73EPQv9BYQYhZrq0=',\n",
       "   'x-amz-request-id': '0CN07PGTH1GKPEFG',\n",
       "   'date': 'Tue, 18 Jan 2022 21:10:27 GMT',\n",
       "   'etag': '\"1474b8e50b5a8d561d11bce90dda066a\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"1474b8e50b5a8d561d11bce90dda066a\"'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_buffer = StringIO()\n",
    "resultattoPandas.to_csv(csv_buffer)\n",
    "s3.Object('imageprojet8oc', 'resultat/resultat.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons enregistrer le modèle et la fonction de prédiction lr, nous pourrons par la suite les récupérer directement et gagner un peu de temps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'DS08FJTTFWAX3CQ9',\n",
       "  'HostId': 'PsC98ZYfNmhhu7oG8vWY2v+mkIJAw4I+rAkP1rFlT0JPXXZf3jhwaWFh8vBpyX3nyv0LqlZrGM4=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'PsC98ZYfNmhhu7oG8vWY2v+mkIJAw4I+rAkP1rFlT0JPXXZf3jhwaWFh8vBpyX3nyv0LqlZrGM4=',\n",
       "   'x-amz-request-id': 'DS08FJTTFWAX3CQ9',\n",
       "   'date': 'Tue, 18 Jan 2022 21:10:31 GMT',\n",
       "   'etag': '\"58791f322c1bfc3de6141788d3b8666f\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"58791f322c1bfc3de6141788d3b8666f\"'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.Object('imageprojet8oc', 'resultat/model.pkl').put(Body = 'model')\n",
    "s3.Object('imageprojet8oc', 'resultat/classificationLR.pkl').put(Body = 'lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons nous attaquer à la partie test, nous avons entraîné nos modèles avec des images à notre disposition, mais nous devons maintenant gérer les nouvelles images qui arriveront, pour cela nous ferons appel à ce que nous avons déjà vu, comme le preprocessing de l'image (modifier la taille de l'image notamment), récupérer les features de l'image et enfin la classifier.\n",
    "\n",
    "C'est ce que nous utiliserons si nous devions par la suite classer de nouvelles images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commencons par charger nos images de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_path = s3://imageprojet8octest/ImageAWSTest/\n"
     ]
    }
   ],
   "source": [
    "img_dir = 's3://imageprojet8octest/ImageAWSTest/'\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(\"imageprojet8oc\")\n",
    "#key = boto.s3.key.Key(bucket, \"words.txt\")\n",
    "\n",
    "print('dataset_path =', img_dir)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dirS3Test = 's3a://imageprojet8octest/ImageAWSTest/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sc.setSystemProperty('com.amazonaws.services.s3.enableV4', 'true')\n",
    "sc._jsc.hadoopConfiguration().set('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:3.2.0')\n",
    "#sc._jsc.hadoopConfiguration().set('spark.jars.packages', 'com.amazonaws:aws-java-sdk:1.12.117')\n",
    "#sc._jsc.hadoopConfiguration().set('spark.jars.packages', 'com.amazonaws:aws-java-sdk-s3-1.12.120')\n",
    "sc._jsc.hadoopConfiguration().set('spark.jars.packages', 'com.amazonaws:aws-java-sdk-core-1.12.134')\n",
    "sc._jsc.hadoopConfiguration().set('spark.jars.packages', 'com.amazonaws:aws-java-sdk-dynamodb-1.12.134')\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.eu-west-3.amazonaws.com\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", AWS_KEY)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", SEC_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesALL_dfTest = spark.read.format(\"binaryFile\") \\\n",
    "                    .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
    "                    .option(\"recursiveFileLookup\", \"true\") \\\n",
    "                    .load(img_dirS3Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+\n",
      "|                path|   modificationTime|length|             content|\n",
      "+--------------------+-------------------+------+--------------------+\n",
      "|s3a://imageprojet...|2022-01-12 20:41:16|  5889|[FF D8 FF E0 00 1...|\n",
      "+--------------------+-------------------+------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imagesALL_dfTest.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelAll0Test = imagesALL_dfTest.withColumn(\"Label0\", split(imagesALL_dfTest['path'], \"//\").getItem(1))\n",
    "imagesALL_dfLabelTest = labelAll0Test.withColumn(\"Label\", split(labelAll0Test['Label0'], \"/\").getItem(2))\n",
    "imagesALL_dfLabelTest = imagesALL_dfLabelTest.select('path', 'content', 'Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|                path|             content| Label|\n",
      "+--------------------+--------------------+------+\n",
      "|s3a://imageprojet...|[FF D8 FF E0 00 1...|Lychee|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imagesALL_dfLabelTest.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_indexerTest = StringIndexer(inputCol=\"Label\", outputCol=\"Label_index\")\n",
    "label_indexer_transformerTest = label_indexerTest.fit(imagesALL_dfLabelTest)\n",
    "imageTest_dfLabelTest = label_indexer_transformerTest.transform(imagesALL_dfLabelTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+-----------+\n",
      "|                path|             content| Label|Label_index|\n",
      "+--------------------+--------------------+------+-----------+\n",
      "|s3a://imageprojet...|[FF D8 FF E0 00 1...|Lychee|        2.0|\n",
      "+--------------------+--------------------+------+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imageTest_dfLabelTest.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessTest(content):\n",
    "    image = PIL.Image.open(io.BytesIO(content))\n",
    "    imageResize = image.resize([224, 224])\n",
    "    imageArray = img_to_array(imageResize)\n",
    "    preprocessingImage = preprocess_input(imageArray)\n",
    "    return preprocessingImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_MobileNetV2():\n",
    "    model = MobileNetV2(include_top = False, input_shape=(224, 224, 3), weights = \"imagenet\", pooling = 'max')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_seriesX(model, content_series):\n",
    "    input = np.stack(content_series.map(preprocessTest))\n",
    "    preds = model.predict(input)\n",
    "    output = [p.flatten() for p in preds]\n",
    "    return pd.Series(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Spark\\spark-3.1.2-bin-hadoop3.2\\python\\pyspark\\sql\\pandas\\functions.py:389: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\n",
    "def featurize_udfX(content_series_iter):\n",
    "    model = model_MobileNetV2()\n",
    "    for content_series in content_series_iter:\n",
    "        yield featurize_seriesX(model, content_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dfTest = imageTest_dfLabelTest.select(\"path\", 'Label', 'Label_index', featurize_udfX(\"content\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[path: string, Label: string, Label_index: double, featurize_udfX(content): array<float>]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dfTest.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dfTest = features_dfTest.withColumnRenamed(\"featurize_udfX(content)\", \"Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dfTest = features_dfTest.withColumn(\"VectorUdt\", conversionVectorUDT('Features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----------+--------------------+--------------------+\n",
      "|                path| Label|Label_index|            Features|           VectorUdt|\n",
      "+--------------------+------+-----------+--------------------+--------------------+\n",
      "|s3a://imageprojet...|Lychee|        2.0|[6.0, 6.0, 1.7463...|[6.0,6.0,1.746314...|\n",
      "+--------------------+------+-----------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_dfTest.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "acp_dfTest = model.transform(features_dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----------+--------------------+--------------------+--------------------+\n",
      "|                path| Label|Label_index|            Features|           VectorUdt|               X_acp|\n",
      "+--------------------+------+-----------+--------------------+--------------------+--------------------+\n",
      "|s3a://imageprojet...|Lychee|        2.0|[6.0, 6.0, 1.7463...|[6.0,6.0,1.746314...|[-35.893827514993...|\n",
      "+--------------------+------+-----------+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acp_dfTest.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = p_model.transform(acp_dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time in seconds: 975.4612152576447\n"
     ]
    }
   ],
   "source": [
    "interval = time.time() - start_time\n",
    "print('Total time in seconds:', interval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
